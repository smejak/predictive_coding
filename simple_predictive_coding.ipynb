{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WAN6IuYj0jZu",
        "outputId": "3f36fa2b-fa86-49df-becf-1ec4532fa82d"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/Bogacz-Group/PredictiveCoding.git\n",
        "! pip install -r PredictiveCoding/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3Qg6jw1M0lSF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "# load predictive coding library\n",
        "import PredictiveCoding.predictive_coding as pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyfc0dF31niX",
        "outputId": "195976f0-9a89-47d1-fe47-14679815958b"
      },
      "outputs": [],
      "source": [
        "n_train = 10000\n",
        "n_val = 500\n",
        "n_test = 5000\n",
        "batch_size = 500\n",
        "\n",
        "# get mnist data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])\n",
        "dataset_train = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
        "dataset_eval = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
        "\n",
        "# Randomly sample the train dataset\n",
        "train_dataset = torch.utils.data.Subset(dataset_train, random.sample(range(len(dataset_train)), n_train))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Randomly sample the val dataset\n",
        "val_dataset, test_dataset, not_used = torch.utils.data.random_split(dataset_eval, [n_val, n_test, dataset_eval.__len__()-n_val-n_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2-5Dm_EL13Er"
      },
      "outputs": [],
      "source": [
        "input_size = 10        # for the 10 classes\n",
        "hidden_size = 256\n",
        "hidden2_size = 256\n",
        "output_size = 28*28    # for the 28 by 28 mnist images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qVOYcUss14hg"
      },
      "outputs": [],
      "source": [
        "activation_fn = nn.ReLU\n",
        "\n",
        "pc_model = nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size),\n",
        "    pc.PCLayer(), # contains neural activity of layer 2\n",
        "    activation_fn(),\n",
        "    nn.Linear(hidden_size, hidden2_size),\n",
        "    pc.PCLayer(), # contains neural activity of layer 3\n",
        "    activation_fn(),\n",
        "    nn.Linear(hidden2_size, output_size)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNk365ds2TRB",
        "outputId": "74cbacbf-b4d6-4909-ce26-5f89bf2fed1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=256, bias=True)\n",
              "  (1): PCLayer()\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (4): PCLayer()\n",
              "  (5): ReLU()\n",
              "  (6): Linear(in_features=256, out_features=784, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pc_model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kZhtwt712Uy0"
      },
      "outputs": [],
      "source": [
        "# number of neural activity updates\n",
        "T = 20\n",
        "# optimizer for activity updates\n",
        "optimizer_x_fn = optim.Adam\n",
        "optimizer_x_kwargs = {'lr': 0.1}\n",
        "\n",
        "# optimizer for weight updates\n",
        "optimizer_p_fn = optim.Adam\n",
        "optimizer_p_kwargs = {\"lr\": 0.001, \"weight_decay\":0.001}\n",
        "\n",
        "trainer = pc.PCTrainer(pc_model, T=T, optimizer_x_fn=optimizer_x_fn, optimizer_x_kwargs=optimizer_x_kwargs, optimizer_p_fn=optimizer_p_fn, optimizer_p_kwargs=optimizer_p_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZAAxPL-v21kk"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "\n",
        "def loss_fn(output, _target):\n",
        "    return 0.5*(output - _target).pow(2).sum()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for data, label in train_loader:\n",
        "        labels_one_hot = F.one_hot(label).float()\n",
        "        trainer.train_on_batch(inputs=labels_one_hot, loss_fn=loss_fn, loss_fn_kwargs={'_target':data}, is_log_progress=False, is_return_results_every_t=False, is_checking_after_callback_after_t=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
